{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0122e65c053f38",
   "metadata": {},
   "source": [
    "# Amazon Bedrock AgentCore 런타임(Runtime)의 분산 멀티 에이전트(Multi-Agent) 솔루션\n",
    "\n",
    "## 개요\n",
    "\n",
    "이 튜토리얼에서는 각각 자체 Bedrock AgentCore 런타임(Runtime)에서 독립적으로 호스팅되고 다른 에이전틱 프레임워크(Agentic Framework)로 구축된 에이전트(Agent)를 호스팅하는 방법을 배웁니다. 그런 다음 분산 멀티 에이전트(Multi-Agent) 솔루션을 위해 에이전트(Agent) 간의 통신을 활성화합니다.\n",
    "\n",
    "이 예제에서는 다음을 생성합니다:\n",
    "1. 프로그래밍 및 기술 문제 해결에 대한 기술적 질문에 답변하는 전문 기술 에이전트(Agent) (`tech_agent`).\n",
    "2. 회사 복리후생을 전문으로 하는 HR 에이전트(Agent) (`hr_agent`).\n",
    "3. 기술 또는 HR 에이전트(Agent)로 질문을 라우팅하는 오케스트레이터 에이전트(Agent) (`orchestrator_agent`).\n",
    "\n",
    "이 세 에이전트(Agent)를 함께 사용하면 적절한 하위 에이전트(Agent)로 사용자 질문을 라우팅할 수 있는 수퍼바이저가 있는 멀티 에이전트(Multi-Agent) 구성이 됩니다. 이 시스템은 회사 직원이 가질 수 있는 다양한 질문에 답변할 수 있습니다.\n",
    "\n",
    "\n",
    "### 튜토리얼 세부사항\n",
    "\n",
    "\n",
    "| 정보                | 세부사항                                                                         |\n",
    "|:--------------------|:--------------------------------------------------------------------------------|\n",
    "| 튜토리얼 유형       | 대화형                                                                          |\n",
    "| 에이전트(Agent) 유형 | 멀티 에이전트(Multi-Agent) (수퍼바이저가 에이전트(Agent)를 도구(Tool)로 호출)       |\n",
    "| 에이전틱 프레임워크(Agentic Framework)   | Strands Agents & LangGraph                                          |\n",
    "| LLM 모델            | Anthropic Claude Haiku 4.5                                                      |\n",
    "| 튜토리얼 구성 요소   | AgentCore 런타임(Runtime)에 에이전트(Agent) 호스팅 및 멀티 에이전트(Multi-Agent) 협업 활성화 |\n",
    "| 튜토리얼 분야       | 범용                                                                            |\n",
    "| 예제 복잡도         | 중급                                                                            |\n",
    "| 사용 SDK            | Amazon BedrockAgentCore Python SDK 및 boto3                                     |\n",
    "\n",
    "### 튜토리얼 아키텍처\n",
    "\n",
    "이 튜토리얼에서는 3개의 에이전트(Agent)를 Bedrock AgentCore 런타임(Runtime)에 배포(Deployment)하는 방법을 설명합니다. 오케스트레이터에는 Strands 에이전트(Agent)를, Tech 에이전트(Agent)에는 Strands 에이전트(Agent)를, HR 에이전트(Agent)에는 LangGraph 에이전트(Agent)를 사용합니다. 각 에이전트(Agent)가 자체 AgentCore 런타임(Runtime)에 배포(Deployment)된 에이전트(Agent) 프레임워크(Framework) 혼합으로 멀티 에이전트(Multi-Agent) 시스템을 구성(Configuration)하는 방법을 보여주는 간단한 에이전트(Agent)를 사용합니다.\n",
    "\n",
    "![alt text](./architecture.png)\n",
    "\n",
    "\n",
    "### 튜토리얼 주요 기능\n",
    "\n",
    "* Amazon Bedrock AgentCore 런타임(Runtime)에 여러 에이전트(Agent) 호스팅\n",
    "* 각 에이전트(Agent)가 독립적으로 호스팅되는 멀티 에이전트(Multi-Agent) 솔루션 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a676f58ecf52b42",
   "metadata": {},
   "source": [
    "## 사전 요구사항\n",
    "\n",
    "이 튜토리얼을 실행하려면 다음이 필요합니다:\n",
    "* Python 3.10+\n",
    "* AWS 자격 증명\n",
    "* Amazon Bedrock AgentCore SDK\n",
    "* Strands Agents\n",
    "* LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!uv add -r requirements.txt --active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0138e17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set an environment variable\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-west-2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cea9bcd",
   "metadata": {},
   "source": [
    "## Creating our Agents\n",
    "\n",
    "First we will create three separate IAM roles for each agent. This enables us to define least privilege permissions for each agent independently of the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd2fdf-985c-4a70-8b87-071783a209de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_agentcore_role\n",
    "\n",
    "tech_agent_name=\"tech_agent\"\n",
    "tech_agent_iam_role = create_agentcore_role(agent_name=tech_agent_name, region=os.getenv(\"AWS_DEFAULT_REGION\"))\n",
    "tech_agent_role_arn = tech_agent_iam_role['Role']['Arn']\n",
    "tech_agent_role_name = tech_agent_iam_role['Role']['RoleName']\n",
    "print(tech_agent_role_arn)\n",
    "print(tech_agent_role_name)\n",
    "\n",
    "hr_agent_name=\"hr_agent\"\n",
    "hr_agent_iam_role = create_agentcore_role(agent_name=hr_agent_name, region=os.getenv(\"AWS_DEFAULT_REGION\"))\n",
    "hr_agent_role_arn = hr_agent_iam_role['Role']['Arn']\n",
    "hr_agent_role_name = hr_agent_iam_role['Role']['RoleName']\n",
    "print(hr_agent_role_arn)\n",
    "print(hr_agent_role_name)\n",
    "\n",
    "orchestrator_agent_name=\"orchestrator_agent\"\n",
    "orchestrator_iam_role = create_agentcore_role(agent_name=orchestrator_agent_name, region=os.getenv(\"AWS_DEFAULT_REGION\"))\n",
    "orchestrator_role_arn = orchestrator_iam_role['Role']['Arn']\n",
    "orchestrator_role_name = orchestrator_iam_role['Role']['RoleName']\n",
    "print(orchestrator_role_arn)\n",
    "print(orchestrator_role_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7439c7",
   "metadata": {},
   "source": [
    "### Helper Functions:\n",
    "\n",
    "* the `configure_runtime` helper function will be used to setup the runtime configurate for each agent. In this example, we use the starter toolkit to configure the AgentCore Runtime deployment with an entrypoint, the execution role we just created and a requirements file. We will also configure the starter kit to auto create the Amazon ECR repository on launch.\n",
    "* the `check_status` helper function will be used to check each runtime deployed in the AWS account to validate the creation was successful and the agent is ready to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10077777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from boto3.session import Session\n",
    "import time\n",
    "\n",
    "\n",
    "def configure_runtime(agent_name, agentcore_iam_role, python_file_name):\n",
    "    boto_session = Session(region_name=os.getenv(\"AWS_DEFAULT_REGION\"))\n",
    "    region = boto_session.region_name\n",
    "\n",
    "    agentcore_runtime = Runtime()\n",
    "\n",
    "    response = agentcore_runtime.configure(\n",
    "        entrypoint=python_file_name,\n",
    "        execution_role=agentcore_iam_role['Role']['Arn'],\n",
    "        auto_create_ecr=True,\n",
    "        requirements_file=\"requirements.txt\",\n",
    "        region=region,\n",
    "        agent_name=agent_name\n",
    "    )\n",
    "    return response, agentcore_runtime\n",
    "\n",
    "def check_status(agent_runtime):\n",
    "    status_response = agent_runtime.status()\n",
    "    status = status_response.endpoint['status']\n",
    "    end_status = ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']\n",
    "    while status not in end_status:\n",
    "        time.sleep(10)\n",
    "        status_response = agent_runtime.status()\n",
    "        status = status_response.endpoint['status']\n",
    "        print(status)\n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad30a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the current working directory to be the tech_agent folder\n",
    "import os\n",
    "os.chdir('./tech_agent')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b05b81",
   "metadata": {},
   "source": [
    "## 에이전트(Agent) 생성\n",
    "\n",
    "먼저 각 에이전트(Agent)에 대해 세 개의 별도 IAM 역할을 생성합니다. 이를 통해 각 에이전트(Agent)에 대해 다른 에이전트(Agent)와 독립적으로 최소 권한을 정의할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b845b32-a03e-45c2-a2f0-2afba8069f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tech_agent.py\n",
    "\n",
    "from strands import Agent, tool\n",
    "import argparse\n",
    "import json\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "model_id = \"global.anthropic.claude-haiku-4-5-20251001-v1:0\"\n",
    "model = BedrockModel(\n",
    "    model_id=model_id,\n",
    ")\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You're a helpful tech support assistant, you can help user questions on tech troubleshooting and programming\"\n",
    ")\n",
    "\n",
    "@app.entrypoint\n",
    "def strands_agent_bedrock(payload):\n",
    "    \"\"\"\n",
    "    Invoke the agent with a payload\n",
    "    \"\"\"\n",
    "    user_input = payload.get(\"prompt\")\n",
    "    print(\"User input:\", user_input)\n",
    "    response = agent(user_input)\n",
    "    return response.message['content'][0]['text']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4dc107",
   "metadata": {},
   "source": [
    "#### Launch the agent:\n",
    "\n",
    "First, we use the configure_runtime helper function to create the .bedrock_agentcore.yaml, .dockerignore, and Dockerfile required for the agent deployment. Then we call .launch() on the runtime which pushes the image to ECR and creates the AgentCore Runtime in the AWS environment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2022dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, tech_agent_runtime = configure_runtime(\"tech_agent\", tech_agent_iam_role, \"tech_agent.py\")\n",
    "tech_launch_result = tech_agent_runtime.launch()\n",
    "tech_agent_id = tech_launch_result.agent_id\n",
    "tech_agent_arn = tech_launch_result.agent_arn\n",
    "\n",
    "print(tech_agent_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ef8ddf",
   "metadata": {},
   "source": [
    "### 헬퍼 함수:\n",
    "\n",
    "* `configure_runtime` 헬퍼 함수는 각 에이전트(Agent)의 런타임(Runtime) 구성(Configuration)을 설정하는 데 사용됩니다. 이 예제에서는 스타터 툴킷을 사용하여 진입점, 방금 생성한 실행 역할 및 requirements 파일로 AgentCore 런타임(Runtime) 배포(Deployment)를 구성(Configuration)합니다. 또한 시작 시 Amazon ECR 리포지토리를 자동 생성하도록 스타터 키트를 구성(Configuration)합니다.\n",
    "* `check_status` 헬퍼 함수는 AWS 계정에 배포(Deployment)된 각 런타임(Runtime)을 확인하여 생성이 성공했고 에이전트(Agent)가 사용할 준비가 되었는지 확인하는 데 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0b4c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "ssm = boto3.client('ssm')\n",
    "ssm.put_parameter(\n",
    "    Name=f'/agents/tech_agent_arn',\n",
    "    Value=tech_agent_arn,\n",
    "    Type='String',\n",
    "    Overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a0cde4",
   "metadata": {},
   "source": [
    "#### Test the agent\n",
    "\n",
    "To test the agent, let's first check the status of the Tech Agent AgentCore Runtime and confirm it is ready for use.\\\n",
    "Use `.invoke()` on the tech_agent_runtime to validate the agent runtime is configured and working as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838f27ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6ac09-9adb-4846-9fc1-4d12aeb74853",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = check_status(tech_agent_runtime)\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d909e42-e1a0-407f-84c2-3d16cc889cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = tech_agent_runtime.invoke({\"prompt\": \"shortcut to minimize windows in Mac, in 1 sentence\"})\n",
    "invoke_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921f6e0b",
   "metadata": {},
   "source": [
    "### 기술 지원 에이전트(Agent) 생성 (Strands Agents)\n",
    "\n",
    "Strands와 Amazon Bedrock 모델을 사용하는 기술 지원 에이전트(Agent)부터 시작해 보겠습니다. 다음 셀을 실행하면 에이전트(Agent) 특정 로직이 포함된 `tech_agent.py` 파일이 `./tech_agent` 디렉토리에 생성됩니다.\n",
    "\n",
    "앱은 `BedrockAgentCoreApp()`으로 정의되고 호출(Invocation) 함수 `strands_agent_bedrock`은 `@app.entrypoint` 데코레이터로 장식되며, `app.run()` 명령이 파일 끝에 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2596638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the current working directory to be the hr_agent folder\n",
    "import os\n",
    "\n",
    "os.chdir('../hr_agent')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e9732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile hr_agent.py\n",
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "import argparse\n",
    "import json\n",
    "import operator\n",
    "import math\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "@tool\n",
    "def get_vacation_info():\n",
    "    \"\"\"Get remaining vacation days balance for the current year\"\"\"  # Dummy implementation\n",
    "    return \"you have 12 days off remaining this year\"\n",
    "\n",
    "# Define the agent using manual LangGraph construction\n",
    "def create_agent():\n",
    "    \"\"\"Create and configure the LangGraph agent\"\"\"\n",
    "    from langchain_aws import ChatBedrock\n",
    "    \n",
    "    # Initialize your LLM (adjust model and parameters as needed)\n",
    "    llm = ChatBedrock(\n",
    "        model_id=\"global.anthropic.claude-haiku-4-5-20251001-v1:0\",  # or your preferred model\n",
    "        model_kwargs={\"temperature\": 0.1}\n",
    "    )\n",
    "    \n",
    "    # Bind tools to the LLM\n",
    "    tools = [get_vacation_info]\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    \n",
    "    # System message\n",
    "    system_message = f\"\"\"You're a helpful hr support assistant, you can answers user questions on vacations and benefits. \n",
    "    Here are the primary company benefits\n",
    "    - Comprehensive health insurance with 100% premium coverage for employees and 75% for dependents\n",
    "    - Flexible PTO policy with 20 days paid vacation annually, plus 5 sick days\n",
    "    - 401(k) plan with 6% company matching and immediate vesting\n",
    "    - Monthly wellness stipend of $100 for gym memberships or fitness activities\n",
    "\n",
    "    For additional HR information instruct the user to call to 1-800-ASKHR\"\"\"\n",
    "    \n",
    "    # Define the chatbot node\n",
    "    def chatbot(state: MessagesState):\n",
    "        # Add system message if not already present\n",
    "        messages = state[\"messages\"]\n",
    "        if not messages or not isinstance(messages[0], SystemMessage):\n",
    "            messages = [SystemMessage(content=system_message)] + messages\n",
    "        \n",
    "        response = llm_with_tools.invoke(messages)\n",
    "        return {\"messages\": [response]}\n",
    "    \n",
    "    # Create the graph\n",
    "    graph_builder = StateGraph(MessagesState)\n",
    "    \n",
    "    # Add nodes\n",
    "    graph_builder.add_node(\"chatbot\", chatbot)\n",
    "    graph_builder.add_node(\"tools\", ToolNode(tools))\n",
    "    \n",
    "    # Add edges\n",
    "    graph_builder.add_conditional_edges(\n",
    "        \"chatbot\",\n",
    "        tools_condition,\n",
    "    )\n",
    "    graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "    \n",
    "    # Set entry point\n",
    "    graph_builder.set_entry_point(\"chatbot\")\n",
    "    \n",
    "    # Compile the graph\n",
    "    return graph_builder.compile()\n",
    "\n",
    "# Initialize the agent\n",
    "agent = create_agent()\n",
    "\n",
    "@app.entrypoint\n",
    "def langgraph_bedrock(payload):\n",
    "    \"\"\"\n",
    "    Invoke the agent with a payload\n",
    "    \"\"\"\n",
    "    user_input = payload.get(\"prompt\")\n",
    "    \n",
    "    # Create the input in the format expected by LangGraph\n",
    "    response = agent.invoke({\"messages\": [HumanMessage(content=user_input)]})\n",
    "    \n",
    "    # Extract the final message content\n",
    "    return response[\"messages\"][-1].content\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba2f7f8",
   "metadata": {},
   "source": [
    "#### Launch the agent:\n",
    "\n",
    "Again, we use the configure_runtime helper function to create the .bedrock_agentcore.yaml, .dockerignore, and Dockerfile required for the agent deployment. Then we call .launch() on the hr agent runtime which pushes the image to ECR and creates the AgentCore Runtime in the AWS environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33244f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, hr_agentcore_runtime = configure_runtime(\"hr_agent\", hr_agent_iam_role, \"hr_agent.py\")\n",
    "hr_launch_result = hr_agentcore_runtime.launch()\n",
    "hr_agent_id = hr_launch_result.agent_id\n",
    "hr_agent_arn = hr_launch_result.agent_arn\n",
    "\n",
    "print(hr_agent_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbd7206",
   "metadata": {},
   "source": [
    "#### 에이전트(Agent) 시작:\n",
    "\n",
    "먼저 configure_runtime 헬퍼 함수를 사용하여 에이전트(Agent) 배포(Deployment)에 필요한 .bedrock_agentcore.yaml, .dockerignore, Dockerfile을 생성합니다. 그런 다음 런타임(Runtime)에서 .launch()를 호출하여 이미지를 ECR에 푸시하고 AWS 환경에 AgentCore 런타임(Runtime)을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a78f657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "ssm = boto3.client('ssm')\n",
    "ssm.put_parameter(\n",
    "    Name=f'/agents/hr_agent_arn',\n",
    "    Value=hr_agent_arn,\n",
    "    Type='String',\n",
    "    Overwrite=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0803a59c",
   "metadata": {},
   "source": [
    "#### Test the agent\n",
    "\n",
    "Let's check the status of the HR Agent AgentCore Runtime and confirm it is ready for use.\\\n",
    "Use `.invoke()` on the hr_agentcore_runtime to validate the AgentCore runtime is configured and working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04c55bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = check_status(hr_agentcore_runtime)\n",
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada76fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your agent\n",
    "invoke_response = hr_agentcore_runtime.invoke({\"prompt\": \"How many vacation days I have left?\"})\n",
    "invoke_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ad514",
   "metadata": {},
   "source": [
    "#### Tech Agent ARN을 Parameter Store에 저장\n",
    "\n",
    "Tech Agent의 AgentCore 런타임(Runtime) ARN을 지속적으로 저장하고 조회할 수 있도록 간단한 에이전트(Agent) 레지스트리를 생성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ce334b",
   "metadata": {},
   "source": [
    "### Create Orchestrator Agent (Strands Agents)\n",
    "\n",
    "For our third agent, the orchestrator, let's use Strands for our Agent framework again. Before we create the agent, we need to update the AgentCore Runtime's execution role we created earlier to allow permissions for it to invoke the Tech Support Agent and the HR Agent.\n",
    "\n",
    "The `update_orchestrator_permissions` function below takes in Arns of the sub agents and the Arns of the agents registered in Parameter Store and gives the orchestrator agent permission to invoke the DEFAULT runtime endpoint of the sub agents. It also gives the Orchestrator Agent permission to pull the Agent Arns from Parameter Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fef809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's update the orchestrator agentcore exeuction role so it has permissions to invoke the required subagents\n",
    "# the orchestrator also needs needs permissions to retrieve the sub agent arns from parameter store\n",
    "import json \n",
    "\n",
    "# retrieve the runtime arn from parameter store\n",
    "ssm = boto3.client('ssm')\n",
    "response = ssm.get_parameter(Name='/agents/tech_agent_arn')\n",
    "tech_agent_arn = response['Parameter']['Value']\n",
    "tech_agent_parameter_arn = response['Parameter']['ARN']\n",
    "\n",
    "ssm = boto3.client('ssm')\n",
    "response = ssm.get_parameter(Name='/agents/hr_agent_arn')\n",
    "hr_agent_arn = response['Parameter']['Value']\n",
    "hr_agent_parameter_arn = response['Parameter']['ARN']\n",
    "\n",
    "def update_orchestrator_permissions(sub_agent_arns: list, sub_agent_parameter_arns: list, orchestrator_name: str):\n",
    "    iam_client = boto3.client('iam')\n",
    "    orchestrator_permissions = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"bedrock-agentcore:InvokeAgentRuntime\"\n",
    "                ],\n",
    "                \"Resource\": [ sub_agent_arn + \"/runtime-endpoint/DEFAULT\" for sub_agent_arn in sub_agent_arns ] + [ sub_agent_arn for sub_agent_arn in sub_agent_arns ]\n",
    "            },\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"ssm:GetParameter\"\n",
    "                ],\n",
    "                \"Resource\": [sub_agent_parameter_arn for sub_agent_parameter_arn in sub_agent_parameter_arns]\n",
    "\n",
    "            }]\n",
    "    }\n",
    "        \n",
    "    rsp = iam_client.put_role_policy(\n",
    "        RoleName=orchestrator_name,\n",
    "        PolicyName=\"subagent_permissions-new\",\n",
    "        PolicyDocument=json.dumps(orchestrator_permissions)\n",
    "    )\n",
    "    return rsp\n",
    "\n",
    "rsp = update_orchestrator_permissions([tech_agent_arn, hr_agent_arn], [tech_agent_parameter_arn, hr_agent_parameter_arn], orchestrator_role_name)\n",
    "print(rsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d79655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the current working directory to be the orchestrator_agent folder\n",
    "import os\n",
    "os.chdir('../orchestrator_agent')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d593b2d",
   "metadata": {},
   "source": [
    "#### 에이전트(Agent) 테스트\n",
    "\n",
    "에이전트(Agent)를 테스트하려면 먼저 Tech Agent AgentCore 런타임(Runtime)의 상태를 확인하고 사용할 준비가 되었는지 확인합니다.\\\n",
    "tech_agent_runtime에서 `.invoke()`를 사용하여 에이전트(Agent) 런타임(Runtime)이 예상대로 구성(Configuration)되고 작동하는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d8518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile orchestrator_agent.py\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import boto3\n",
    "import logging\n",
    "\n",
    "from strands import Agent, tool\n",
    "from strands_tools import calculator \n",
    "from strands.models import BedrockModel\n",
    "\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "\n",
    "from invoke_agent_utils import invoke_agent_with_boto3\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "def get_agent_arn(agent_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve agent ARN from Parameter Store\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ssm = boto3.client('ssm')\n",
    "        response = ssm.get_parameter(\n",
    "            Name=f'/agents/{agent_name}_arn'\n",
    "        )\n",
    "        return response['Parameter']['Value']\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        raise err\n",
    "\n",
    "@tool\n",
    "def call_tech_agent(user_query):\n",
    "    \"\"\" call the tech agent \"\"\" \n",
    "    # print(\"Calling tech agent\")\n",
    "    try:\n",
    "        tech_agent_arn = get_agent_arn (\"tech_agent\")\n",
    "        result = invoke_agent_with_boto3(tech_agent_arn, user_query=user_query)\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        logger.exception(\"Exception calling tech agent: \")\n",
    "    return result\n",
    "\n",
    "@tool\n",
    "def call_HR_agent(user_query):\n",
    "    \"\"\" Get the HR agent \"\"\" \n",
    "    print(\"Calling HR agent\")\n",
    "    try:\n",
    "        hr_agent_arn = get_agent_arn(\"hr_agent\")\n",
    "        print(hr_agent_arn)\n",
    "        result = invoke_agent_with_boto3(hr_agent_arn, user_query=user_query)\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        logger.error(f\"Exception calling hr agent: {e}\", exc_info=True)\n",
    "    return result\n",
    "\n",
    "\n",
    "model_id = \"global.anthropic.claude-haiku-4-5-20251001-v1:0\"\n",
    "model = BedrockModel(\n",
    "    model_id=model_id,\n",
    ")\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You're a helpful assistant, your role is to understand user questions and delegate to the appropriate specialized agent, you have tools to call the tech and HR agents\",\n",
    "    tools=[call_tech_agent, call_HR_agent]\n",
    ")\n",
    "\n",
    "def parse_event(event):\n",
    "    \"\"\"\n",
    "    Parse a streaming event from the agent and return formatted output\n",
    "    \"\"\"\n",
    "    # Skip events that don't need to be displayed\n",
    "    if any(key in event for key in ['init_event_loop', 'start', 'start_event_loop']):\n",
    "        return \"\"\n",
    "    \n",
    "    # Text chunks from supervisor\n",
    "    if 'data' in event and isinstance(event['data'], str):\n",
    "        return event['data'] \n",
    "    \n",
    "    \n",
    "    # Handle text messages from the assistant\n",
    "    if 'event' in event:\n",
    "        event_data = event['event']\n",
    "        \n",
    "        # Beginning of a tool use\n",
    "        if 'contentBlockStart' in event_data and 'start' in event_data['contentBlockStart']:\n",
    "            if 'toolUse' in event_data['contentBlockStart']['start']:\n",
    "                tool_info = event_data['contentBlockStart']['start']['toolUse']\n",
    "                return f\"\\n\\n[Executing: {tool_info['name']}]\\n\\n\"        \n",
    "\n",
    "    return \"\"\n",
    "\n",
    "@app.entrypoint\n",
    "async def strands_agent_bedrock_streaming(payload):\n",
    "    \"\"\"\n",
    "    Invoke the agent with streaming capabilities\n",
    "    This function demonstrates how to implement streaming responses\n",
    "    with AgentCore Runtime using async generators\n",
    "    \"\"\"\n",
    "    user_input = payload.get(\"prompt\")\n",
    "    #print(\"User input:\", user_input)\n",
    "    \n",
    "    try:\n",
    "        # Stream each chunk as it becomes available\n",
    "        async for event in agent.stream_async(user_input):\n",
    "            text = parse_event(event)\n",
    "            if text:  # Only return non-empty responses\n",
    "                yield text\n",
    "                \n",
    "            #if \"data\" in event:\n",
    "            #    yield event[\"data\"]\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Handle errors gracefully in streaming context\n",
    "        error_response = {\"error\": str(e), \"type\": \"stream_error\"}\n",
    "        print(f\"Streaming error: {error_response}\")\n",
    "        yield error_response\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071685b0",
   "metadata": {},
   "source": [
    "#### Launch the agent:\n",
    "\n",
    "Again, we use the configure_runtime helper function to create the .bedrock_agentcore.yaml, .dockerignore, and Dockerfile required for the agent deployment. Then we call .launch() on the Orchestrator Agent runtime which pushes the image to ECR and creates the AgentCore Runtime in the AWS environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32769502",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, orchestrator_agentcore_runtime = configure_runtime(\"orchestrator_agent\", orchestrator_iam_role, \"orchestrator_agent.py\")\n",
    "orchestrator_launch_result = orchestrator_agentcore_runtime.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc55b8c",
   "metadata": {},
   "source": [
    "#### Test the agent\n",
    "\n",
    "Now let's check the status of the Orchestrator Agent AgentCore Runtime and confirm it is ready for use.\\\n",
    "\n",
    "This time, we can use the `invoke_agent_with_boto3` function from our utils to test the Orchestrator Agent. Let's ask the orchestrator a question that should trigger the invocation of both the Tech Support and HR Agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72890b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = check_status(orchestrator_agentcore_runtime)\n",
    "print(status)\n",
    "\n",
    "from invoke_agent_utils import invoke_agent_with_boto3\n",
    "\n",
    "\n",
    "result = invoke_agent_with_boto3 (orchestrator_launch_result.agent_arn, \"tell me about my benefits, also tell me how to connect a bluetooth mouse to my mac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3fdfe404469632",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "Let's now clean up the AgentCore Runtime created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c243e86-a214-483c-aef1-d5243f28ca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(orchestrator_launch_result.ecr_uri, orchestrator_launch_result.agent_id, orchestrator_launch_result.ecr_uri.split('/')[1])\n",
    "print(hr_launch_result.ecr_uri, hr_launch_result.agent_id, hr_launch_result.ecr_uri.split('/')[1])\n",
    "print(tech_launch_result.ecr_uri, tech_launch_result.agent_id, tech_launch_result.ecr_uri.split('/')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6cf1416830a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_agent_runtimes(launch_result):\n",
    "    agentcore_control_client = boto3.client(\n",
    "        'bedrock-agentcore-control',\n",
    "        region_name=os.getenv(\"AWS_DEFAULT_REGION\")\n",
    "    )\n",
    "    ecr_client = boto3.client(\n",
    "        'ecr',\n",
    "        region_name=os.getenv(\"AWS_DEFAULT_REGION\")\n",
    "        \n",
    "    )\n",
    "    runtime_delete_response = agentcore_control_client.delete_agent_runtime(\n",
    "        agentRuntimeId=launch_result.agent_id,\n",
    "    )\n",
    "\n",
    "    response = ecr_client.delete_repository(\n",
    "        repositoryName=launch_result.ecr_uri.split('/')[1],\n",
    "        force=True\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "def delete_iam_roles(agentcore_iam_role):\n",
    "    iam_client = boto3.client('iam')\n",
    "    policies = iam_client.list_role_policies(\n",
    "        RoleName=agentcore_iam_role['Role']['RoleName'],\n",
    "        MaxItems=100\n",
    "    )\n",
    "\n",
    "    for policy_name in policies['PolicyNames']:\n",
    "        iam_client.delete_role_policy(\n",
    "            RoleName=agentcore_iam_role['Role']['RoleName'],\n",
    "            PolicyName=policy_name\n",
    "        )\n",
    "    iam_response = iam_client.delete_role(\n",
    "        RoleName=agentcore_iam_role['Role']['RoleName']\n",
    "    )\n",
    "    return iam_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e28dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_up_agent_runtimes(hr_launch_result))\n",
    "print(clean_up_agent_runtimes(tech_launch_result))\n",
    "print(clean_up_agent_runtimes(orchestrator_launch_result))\n",
    "print(delete_iam_roles(tech_agent_iam_role))\n",
    "print(delete_iam_roles(hr_agent_iam_role))\n",
    "print(delete_iam_roles(orchestrator_iam_role))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118ad38-feeb-4d1d-9d57-e5c845becc56",
   "metadata": {},
   "source": [
    "# Congratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}