{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0122e65c053f38",
   "metadata": {},
   "source": [
    "# Amazon Bedrock AgentCore 런타임(Runtime)에서 OpenAI 모델을 사용한 Strands 에이전트(Agent) 호스팅\n",
    "\n",
    "## 개요\n",
    "\n",
    "이 튜토리얼에서는 Amazon Bedrock AgentCore 런타임(Runtime)을 사용하여 기존 에이전트(Agent)를 호스팅하는 방법을 배웁니다.\n",
    "\n",
    "OpenAI 모델을 사용한 Strands 에이전트(Agent) 예제에 초점을 맞출 것입니다. Amazon Bedrock 모델을 사용한 Strands 에이전트(Agent)는 [여기](../01-strands-with-bedrock-model)를, Amazon Bedrock 모델을 사용한 LangGraph는 [여기](../02-langgraph-with-bedrock-model)를 확인하세요.\n",
    "\n",
    "\n",
    "### 튜토리얼 세부사항\n",
    "\n",
    "| 정보               | 세부사항                                                                 |\n",
    "|:--------------------|:------------------------------------------------------------------------|\n",
    "| 튜토리얼 유형       | 대화형                                                                  |\n",
    "| 에이전트(Agent) 유형 | 단일                                                                    |\n",
    "| 에이전틱 프레임워크(Agentic Framework) | Strands Agents                                        |\n",
    "| LLM 모델            | GPT 4.1 mini                                                            |\n",
    "| 튜토리얼 구성 요소   | AgentCore 런타임(Runtime)에 에이전트(Agent) 호스팅. Strands Agent와 OpenAI 모델 사용 |\n",
    "| 튜토리얼 분야       | 범용                                                                    |\n",
    "| 예제 복잡도         | 쉬움                                                                    |\n",
    "| 사용 SDK            | Amazon BedrockAgentCore Python SDK 및 boto3                             |\n",
    "\n",
    "### 튜토리얼 아키텍처\n",
    "\n",
    "이 튜토리얼에서는 기존 에이전트(Agent)를 AgentCore 런타임(Runtime)에 배포(Deployment)하는 방법을 설명합니다.\n",
    "\n",
    "데모 목적으로 Amazon Bedrock 모델을 사용하는 Strands 에이전트(Agent)를 사용할 것입니다.\n",
    "\n",
    "예제에서는 `get_weather`와 `get_time` 두 가지 도구(Tool)를 가진 매우 간단한 에이전트(Agent)를 사용합니다.\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture_runtime.png\" width=\"60%\"/>\n",
    "</div>\n",
    "\n",
    "### 튜토리얼 주요 기능\n",
    "\n",
    "* Amazon Bedrock AgentCore 런타임(Runtime)에 에이전트(Agent) 호스팅\n",
    "* OpenAI 모델 사용\n",
    "* Strands 에이전트(Agent) 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a676f58ecf52b42",
   "metadata": {},
   "source": [
    "## 사전 요구사항\n",
    "\n",
    "이 튜토리얼을 실행하려면 다음이 필요합니다:\n",
    "* Python 3.10+\n",
    "* AWS 자격 증명\n",
    "* Amazon Bedrock AgentCore SDK\n",
    "* Strands Agents\n",
    "* Docker 실행 중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": "!pip install --force-reinstall -U -r requirements.txt --quiet"
  },
  {
   "cell_type": "markdown",
   "id": "ca924a7a2731e26f",
   "metadata": {},
   "source": [
    "## Creating your agents and experimenting locally\n",
    "\n",
    "Before we deploy our agents to AgentCore Runtime, let's develop and run them locally for experimentation purposes.\n",
    "\n",
    "For production agentic applications we will need to decouple the agent creation process from the agent invocation one. With AgentCore Runtime, we will decorate the invocation part of our agent with the `@app.entrypoint` decorator and have it as the entry point for our runtime. Let's first look how each agent is developed during the experimentation phase.\n",
    "\n",
    "The architecture here will look as following:\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture_local.png\" width=\"60%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d386ab54e85e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile strands_agents_openai.py\n",
    "from strands import Agent, tool\n",
    "from strands_tools import calculator # Import the calculator tool\n",
    "import argparse\n",
    "import json\n",
    "from strands.models.litellm import LiteLLMModel\n",
    "import os\n",
    "\n",
    "os.environ[\"AZURE_API_KEY\"] = \"<YOUR_API_KEY>\"\n",
    "os.environ[\"AZURE_API_BASE\"] = \"<YOUR_API_BASE>\"\n",
    "os.environ[\"AZURE_API_VERSION\"] = \"<YOUR_API_VERSION>\"\n",
    "\n",
    "# Create a custom tool \n",
    "@tool\n",
    "def weather():\n",
    "    \"\"\" Get weather \"\"\" # Dummy implementation\n",
    "    return \"sunny\"\n",
    "\n",
    "model = \"azure/gpt-4.1-mini\"\n",
    "litellm_model = LiteLLMModel(\n",
    "    model_id=model, params={\"max_tokens\": 32000, \"temperature\": 0.7}\n",
    ")\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    model=litellm_model,\n",
    "    tools=[calculator, weather],\n",
    "    system_prompt=\"You're a helpful assistant. You can do simple math calculation, and tell the weather.\"\n",
    ")\n",
    "\n",
    "def strands_agent_open_ai(payload):\n",
    "    \"\"\"\n",
    "    Invoke the agent with a payload\n",
    "    \"\"\"\n",
    "    user_input = payload.get(\"prompt\")\n",
    "    response = agent(user_input)\n",
    "    return response.message['content'][0]['text']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"payload\", type=str)\n",
    "    args = parser.parse_args()\n",
    "    response = strands_agent_open_ai(json.loads(args.payload))\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68499675-db8d-47c6-8c0c-5d66dcb06229",
   "metadata": {},
   "source": [
    "## 에이전트(Agent) 생성 및 로컬에서 실험하기\n",
    "\n",
    "에이전트(Agent)를 AgentCore 런타임(Runtime)에 배포(Deployment)하기 전에 실험 목적으로 로컬에서 개발하고 실행해 보겠습니다.\n",
    "\n",
    "프로덕션 에이전틱 애플리케이션의 경우 에이전트(Agent) 생성 프로세스와 에이전트(Agent) 호출(Invocation) 프로세스를 분리해야 합니다. AgentCore 런타임(Runtime)에서는 에이전트(Agent)의 호출(Invocation) 부분을 `@app.entrypoint` 데코레이터로 장식하고 이를 런타임(Runtime)의 진입점으로 사용합니다. 먼저 실험 단계에서 각 에이전트(Agent)가 어떻게 개발되는지 살펴보겠습니다.\n",
    "\n",
    "여기서 아키텍처는 다음과 같습니다:\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture_local.png\" width=\"60%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1226d59e6b56c96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:52:06.461281Z",
     "start_time": "2025-06-29T21:52:06.456854Z"
    }
   },
   "outputs": [],
   "source": [
    "!python strands_agents_openai.py '{\"prompt\": \"What is the weather now?\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932110e6-fca6-47b6-b7c5-c4714a866a80",
   "metadata": {},
   "source": [
    "## Preparing your agent for deployment on AgentCore Runtime\n",
    "\n",
    "Let's now deploy our agents to AgentCore Runtime. To do so we need to:\n",
    "* Import the Runtime App with `from bedrock_agentcore.runtime import BedrockAgentCoreApp`\n",
    "* Initialize the App in our code with `app = BedrockAgentCoreApp()`\n",
    "* Decorate the invocation function with the `@app.entrypoint` decorator\n",
    "* Let AgentCoreRuntime control the running of the agent with `app.run()`\n",
    "\n",
    "### Strands Agents with OpenAI model\n",
    "Let's start with our Strands Agent using the GPT 4.1 mini model. All the others will work exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b845b32-a03e-45c2-a2f0-2afba8069f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile strands_agents_openai.py\n",
    "from strands import Agent, tool\n",
    "from strands_tools import calculator # Import the calculator tool\n",
    "import argparse\n",
    "import json\n",
    "from strands.models.litellm import LiteLLMModel\n",
    "import os\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "os.environ[\"AZURE_API_KEY\"] = \"<YOUR_API_KEY>\"\n",
    "os.environ[\"AZURE_API_BASE\"] = \"<YOUR_API_BASE>\"\n",
    "os.environ[\"AZURE_API_VERSION\"] = \"<YOUR_API_VERSION>\"\n",
    "\n",
    "# Create a custom tool \n",
    "@tool\n",
    "def weather():\n",
    "    \"\"\" Get weather \"\"\" # Dummy implementation\n",
    "    return \"sunny\"\n",
    "\n",
    "model = \"azure/gpt-4.1-mini\"\n",
    "litellm_model = LiteLLMModel(\n",
    "    model_id=model, params={\"max_tokens\": 32000, \"temperature\": 0.7}\n",
    ")\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    model=litellm_model,\n",
    "    tools=[calculator, weather],\n",
    "    system_prompt=\"You're a helpful assistant. You can do simple math calculation, and tell the weather.\"\n",
    ")\n",
    "\n",
    "\n",
    "@app.entrypoint\n",
    "def strands_agent_open_ai(payload):\n",
    "    \"\"\"\n",
    "    Invoke the agent with a payload\n",
    "    \"\"\"\n",
    "    user_input = payload.get(\"prompt\")\n",
    "    response = agent(user_input)\n",
    "    return response.message['content'][0]['text']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64db7b5-0f1b-475f-9bf2-467b4449d46a",
   "metadata": {},
   "source": [
    "#### 로컬 에이전트(Agent) 호출(Invocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6820ca8f-a8a8-4f34-b4ef-b6dad3776261",
   "metadata": {},
   "source": [
    "## Deploying the agent to AgentCore Runtime\n",
    "\n",
    "The `CreateAgentRuntime` operation supports comprehensive configuration options, letting you specify container images, environment variables and encryption settings. You can also configure protocol settings (HTTP, MCP) and authorization mechanisms to control how your clients communicate with the agent. \n",
    "\n",
    "**Note:** Operations best practice is to package code as container and push to ECR using CI/CD pipelines and IaC\n",
    "\n",
    "In this tutorial can will the Amazon Bedrock AgentCode Python SDK to easily package your artifacts and deploy them to AgentCore runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8855aceb-b79f-4aaa-b16f-8577c059816a",
   "metadata": {},
   "source": [
    "## AgentCore 런타임(Runtime) 배포(Deployment)를 위한 에이전트(Agent) 준비\n",
    "\n",
    "이제 에이전트(Agent)를 AgentCore 런타임(Runtime)에 배포(Deployment)해 보겠습니다. 이를 위해 다음이 필요합니다:\n",
    "* `from bedrock_agentcore.runtime import BedrockAgentCoreApp`으로 Runtime App 임포트\n",
    "* 코드에서 `app = BedrockAgentCoreApp()`으로 App 초기화\n",
    "* 호출(Invocation) 함수를 `@app.entrypoint` 데코레이터로 장식\n",
    "* `app.run()`으로 AgentCoreRuntime이 에이전트(Agent) 실행을 제어하도록 함\n",
    "\n",
    "### OpenAI 모델을 사용한 Strands 에이전트(Agent)\n",
    "GPT 4.1 mini 모델을 사용하는 Strands 에이전트(Agent)부터 시작해 보겠습니다. 다른 모든 것도 정확히 동일하게 작동합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e79eba2-ca59-463f-9ebf-56e362d7ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from boto3.session import Session\n",
    "import boto3\n",
    "import json\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "\n",
    "agentcore_runtime = Runtime()\n",
    "\n",
    "agent_name = \"strands_openai_getting_started\"\n",
    "response = agentcore_runtime.configure(\n",
    "    entrypoint=\"strands_agents_openai.py\",\n",
    "    auto_create_execution_role=True,\n",
    "    auto_create_ecr=True,\n",
    "    requirements_file=\"requirements.txt\",\n",
    "    region=region,\n",
    "    agent_name=agent_name\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1b84cc-798e-472c-ac0b-2c315f4b704d",
   "metadata": {},
   "source": [
    "### Launching agent to AgentCore Runtime\n",
    "\n",
    "Now that we've got a docker file, let's launch the agent to the AgentCore Runtime. This will create the Amazon ECR repository and the AgentCore Runtime\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/launch.png\" width=\"85%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a32ab8-7701-4900-8055-e24364bdf35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_result = agentcore_runtime.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae9c09-09db-4a76-871a-92eacd96b9c3",
   "metadata": {},
   "source": [
    "## 내부적으로 무슨 일이 일어나나요?\n",
    "\n",
    "`BedrockAgentCoreApp`을 사용하면 자동으로:\n",
    "\n",
    "* 포트 8080에서 수신 대기하는 HTTP 서버 생성\n",
    "* 에이전트(Agent) 요구사항 처리를 위한 필수 `/invocations` 엔드포인트(Endpoint) 구현\n",
    "* 헬스 체크를 위한 `/ping` 엔드포인트(Endpoint) 구현 (비동기 에이전트(Agent)에 매우 중요)\n",
    "* 적절한 콘텐츠 타입 및 응답 형식 처리\n",
    "* AWS 표준에 따른 오류 처리 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6ac09-9adb-4846-9fc1-4d12aeb74853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "status_response = agentcore_runtime.status()\n",
    "status = status_response.endpoint['status']\n",
    "end_status = ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']\n",
    "while status not in end_status:\n",
    "    time.sleep(10)\n",
    "    status_response = agentcore_runtime.status()\n",
    "    status = status_response.endpoint['status']\n",
    "    print(status)\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f89c56-918a-4cab-beaa-c7ac43a2ba29",
   "metadata": {},
   "source": [
    "## AgentCore 런타임(Runtime)에 에이전트(Agent) 배포(Deployment)\n",
    "\n",
    "`CreateAgentRuntime` 작업은 포괄적인 구성(Configuration) 옵션을 지원하여 컨테이너 이미지, 환경 변수 및 암호화 설정을 지정할 수 있습니다. 또한 프로토콜 설정(HTTP, MCP)과 인가(Authorization) 메커니즘을 구성(Configuration)하여 클라이언트가 에이전트(Agent)와 통신하는 방식을 제어할 수 있습니다.\n",
    "\n",
    "**참고:** 운영 모범 사례는 코드를 컨테이너로 패키징하고 CI/CD 파이프라인 및 IaC를 사용하여 ECR에 푸시하는 것입니다.\n",
    "\n",
    "이 튜토리얼에서는 Amazon Bedrock AgentCode Python SDK를 사용하여 아티팩트를 쉽게 패키징하고 AgentCore 런타임(Runtime)에 배포(Deployment)할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d909e42-e1a0-407f-84c2-3d16cc889cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = agentcore_runtime.invoke({\"prompt\": \"Hi, what can you do?\"})\n",
    "invoke_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa09f2-d25a-483f-aedb-11690bb8923a",
   "metadata": {},
   "source": [
    "### AgentCore 런타임(Runtime) 배포(Deployment) 구성(Configuration)\n",
    "\n",
    "다음으로 스타터 툴킷을 사용하여 진입점, 방금 생성한 실행 역할 및 requirements 파일로 AgentCore 런타임(Runtime) 배포(Deployment)를 구성(Configuration)합니다. 또한 시작 시 Amazon ECR 리포지토리를 자동 생성하도록 스타터 키트를 구성(Configuration)합니다.\n",
    "\n",
    "구성(Configuration) 단계에서 애플리케이션 코드를 기반으로 도커 파일이 생성됩니다.\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/configure.png\" width=\"60%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11249103-cfb3-47b5-970d-981a977a225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import json\n",
    "response_text = invoke_response['response'][0]\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1d2bce-be41-478c-8bed-b4037c385795",
   "metadata": {},
   "source": [
    "### Invoking AgentCore Runtime with boto3\n",
    "\n",
    "Now that your AgentCore Runtime was created you can invoke it with any AWS SDK. For instance, you can use the boto3 `invoke_agent_runtime` method for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f84e68d-6c04-41b9-bf5b-60edc3fa0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "agent_arn = launch_result.agent_arn\n",
    "agentcore_client = boto3.client(\n",
    "    'bedrock-agentcore',\n",
    "    region_name=region\n",
    ")\n",
    "\n",
    "boto3_response = agentcore_client.invoke_agent_runtime(\n",
    "    agentRuntimeArn=agent_arn,\n",
    "    qualifier=\"DEFAULT\",\n",
    "    payload=json.dumps({\"prompt\": \"How much is 2X2?\"})\n",
    ")\n",
    "if \"text/event-stream\" in boto3_response.get(\"contentType\", \"\"):\n",
    "    content = []\n",
    "    for line in boto3_response[\"response\"].iter_lines(chunk_size=1):\n",
    "        if line:\n",
    "            line = line.decode(\"utf-8\")\n",
    "            if line.startswith(\"data: \"):\n",
    "                line = line[6:]\n",
    "                print(line)\n",
    "                content.append(line)\n",
    "    display(Markdown(\"\\n\".join(content)))\n",
    "else:\n",
    "    try:\n",
    "        events = []\n",
    "        for event in boto3_response.get(\"response\", []):\n",
    "            events.append(event)\n",
    "    except Exception as e:\n",
    "        events = [f\"Error reading EventStream: {e}\"]\n",
    "    display(Markdown(json.loads(events[0].decode(\"utf-8\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3fdfe404469632",
   "metadata": {},
   "source": [
    "### AgentCore 런타임(Runtime)에 에이전트(Agent) 시작\n",
    "\n",
    "이제 도커 파일이 준비되었으니 에이전트(Agent)를 AgentCore 런타임(Runtime)에 시작해 보겠습니다. 이렇게 하면 Amazon ECR 리포지토리와 AgentCore 런타임(Runtime)이 생성됩니다.\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/launch.png\" width=\"85%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6cf1416830a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "agentcore_control_client = boto3.client(\n",
    "    'bedrock-agentcore-control',\n",
    "    region_name=region\n",
    ")\n",
    "ecr_client = boto3.client(\n",
    "    'ecr',\n",
    "    region_name=region\n",
    "    \n",
    ")\n",
    "\n",
    "runtime_delete_response = agentcore_control_client.delete_agent_runtime(\n",
    "    agentRuntimeId=launch_result.agent_id\n",
    ")\n",
    "\n",
    "response = ecr_client.delete_repository(\n",
    "    repositoryName=launch_result.ecr_uri.split('/')[1],\n",
    "    force=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118ad38-feeb-4d1d-9d57-e5c845becc56",
   "metadata": {},
   "source": [
    "# Congratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}